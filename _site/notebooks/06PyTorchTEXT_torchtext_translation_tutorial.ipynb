{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06PyTorchTEXT_torchtext_translation_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JPA-BERT/jpa-bert.github.io/blob/master/notebooks/06PyTorchTEXT_torchtext_translation_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Dl3E5gvYLW-",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "    \n",
        "このファイルは PyTorch のチュートリアルにあるファイル <https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html> を翻訳して，加筆修正したもの\n",
        "です。\n",
        "\n",
        "すぐれたチュートリアルの内容，コードを公開された Ben Trevett, Seth Widman および PyTorch 開発陣に敬意を表します。\n",
        "\n",
        "- Original: \n",
        "- Date: 2020-0811\n",
        "- Translated and modified: Shin Asakawa <asakawa@ieee.org>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaVjgEsIZDbL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "acdd4c50-9568-42c2-f365-bab5502a0a1f"
      },
      "source": [
        "# 2020年8月11日現在 torchtext を upgrade しないとこのノートブックは動作しません。\n",
        "!pip install --upgrade torchtext"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f9/224b3893ab11d83d47fde357a7dcc75f00ba219f34f3d15e06fe4cb62e05/torchtext-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (4.5MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.6.0+cu101)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from torchtext) (2.23.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 55.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext) (2.10)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.91 torchtext-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torchtext"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLJoCLMLYLXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from https://github.com/dmlc/xgboost/issues/1715\n",
        "import os\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6CaBM8DCjrkp",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c347f8kUjrk0"
      },
      "source": [
        "# TorchText による言語翻訳\n",
        "<!--\n",
        "# Language Translation with TorchText\n",
        "-->\n",
        "\n",
        "<!--\n",
        "This tutorial shows how to use several convenience classes of ``torchtext`` to preprocess data from a well-known dataset containing sentences in both English and German and use it to train a sequence-to-sequence model with attention that can translate German sentences into English.\n",
        "-->\n",
        "\n",
        "このチュートリアルでは，英語とドイツ語の両方の文を含むよく知られたデータセットからのデータの前処理し，ドイツ語の文を英語に翻訳できるように注意を使った系列-to-系列 (seq2seq) モデルを訓練します。このため ``torchtext`` のいくつかの便利なクラスを使用する方法を示します。\n",
        "\n",
        "<!--\n",
        "It is based off of [this tutorial](https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb) from PyTorch community member [Ben Trevett](https://github.com/bentrevett) and was created by [Seth Weidman](https://github.com/SethHWeidman/) with Ben's permission.\n",
        "-->\n",
        "\n",
        "このチュートリアルは PyTorch コミュニティメンバーの [Ben Trevett](https://github.com/bentrevett) の [チュートリアル](https://github.com/bentrevett/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb) をベースにしています。\n",
        "Ben の許可を得て [Seth Weidman](https://github.com/SethHWeidman/) によって作成されました。\n",
        "\n",
        "\n",
        "このチュートリアルを終えると，以下のことができるようになります。\n",
        "\n",
        "- 以下 ``torchtext`` 便利なクラスを使って NLP モデリングのために一般的に使われている形式に文を前処理\n",
        "    - [TranslationDataset](https://torchtext.readthedocs.io/en/latest/datasets.html#torchtext.datasets.TranslationDataset)\n",
        "    - [Field](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Field)\n",
        "    - [BucketIterator](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.BucketIterator)\n",
        "\n",
        "<!--\n",
        "By the end of this tutorial, you will be able to:\n",
        "\n",
        "- Preprocess sentences into a commonly-used format for NLP modeling using the following ``torchtext`` convenience classes:\n",
        "    - [TranslationDataset](https://torchtext.readthedocs.io/en/latest/datasets.html#torchtext.datasets.TranslationDataset)\n",
        "    - [Field](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Field)\n",
        "    - [BucketIterator](https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.BucketIterator)\n",
        "-->\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aji0vtGwjrk1"
      },
      "source": [
        "<!-- ## `Field` and `TranslationDataset`-->\n",
        "## `Field` と `TranslationDataset`\n",
        "\n",
        "<!--\n",
        "``torchtext`` has utilities for creating datasets that can be easily iterated through for the purposes of creating a language translation model. \n",
        "One key class is a [Field](https://github.com/pytorch/text/blob/master/torchtext/data/field.py#L64), which specifies the way each sentence should be preprocessed, and another is the `TranslationDataset` ; ``torchtext`` has several such datasets; in this tutorial we'll use the [Multi30k dataset](https://github.com/multi30k/dataset), which contains about 30,000 sentences (averaging about 13 words in length) in both English and German.\n",
        "-->\n",
        "\n",
        "``torchtext`` には，言語翻訳モデルを作成する目的で簡単に反復処理できるデータセットを作成するためのユーティリティが用意されています。\n",
        "キーとなるクラスの一つは [Field](https://github.com/pytorch/text/blob/master/torchtext/data/field.py#L64) です。\n",
        "Field を用いて各文をどのように前処理するかを指定することができます。\n",
        "\n",
        "<!--\n",
        "Note: the tokenization in this tutorial requires [Spacy](https://spacy.io).\n",
        "We use Spacy because it provides strong support for tokenization in languages other than English. \n",
        "``torchtext`` provides a ``basic_english`` tokenizer and supports other tokenizers for English (e.g. [Moses](https://bitbucket.org/luismsgomes/mosestokenizer/src/default/) but for language translation - where multiple languages are required - Spacy is your best bet. \n",
        "-->\n",
        "\n",
        "注意: このチュートリアルのトークン化には [Spacy](https://spacy.io) が必要です。\n",
        "Spacy を使うのは，英語以外の言語でのトークン化を強力にサポートしているからです。\n",
        "``torchtext`` は ``basic_english`` のトークン化機能を提供しています。\n",
        "他のトークン化機能もサポートしています\n",
        "(例: [Moses](https://bitbucket.org/luismsgomes/mosestokenizer/src/default/) \n",
        "複数の言語翻訳が必要な場合には Spacy を使うのが一番です。\n",
        "\n",
        "To run this tutorial, first install ``spacy`` using ``pip`` or ``conda``. \n",
        "Next, download the raw data for the English and German Spacy tokenizers:\n",
        "\n",
        "このチュートリアルを実行するには まず ``spacy`` を ``pip`` または ``conda`` を使ってインストールします。\n",
        "次に，英語とドイツ語の Spacy トークナイザーで使用する生データをダウンロードします。\n",
        "\n",
        "```bash\n",
        "$python -m spacy download en\n",
        "$python -m spacy download de\n",
        "```\n",
        "\n",
        "<!--\n",
        "With Spacy installed, the following code will tokenize each of the sentences in the ``TranslationDataset`` based on the tokenizer defined in the ``Field``\n",
        "-->\n",
        "\n",
        "Spacy をインストールすると，以下のコードは ``Field`` で定義されたトークン化方式に基づいて ``TranslationDataset`` の各文をトークン化します。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8-gJ_X1YLXN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        },
        "outputId": "5270bd1d-16a0-44e3-f459-26b067b3130b"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download de"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (49.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "Requirement already satisfied: de_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz#egg=de_core_news_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.7.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (49.2.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p68BR8PWjrk6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d961f748-8064-482e-ed79-0eac9c587141"
      },
      "source": [
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "\n",
        "SRC = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"de\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "TRG = Field(tokenize = \"spacy\",\n",
        "            tokenizer_language=\"en\",\n",
        "            init_token = '<sos>',\n",
        "            eos_token = '<eos>',\n",
        "            lower = True)\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'),\n",
        "                                                    fields = (SRC, TRG))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "training.tar.gz:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:00<00:00, 5.67MB/s]\n",
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 1.68MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n",
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 1.36MB/s]\n",
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rzoNI5COjrk9"
      },
      "source": [
        "<!--\n",
        "Now that we've defined ``train_data``, we can see an extremely useful feature of ``torchtext``'s ``Field``: the ``build_vocab`` method now allows us to create the vocabulary associated with each language\n",
        "-->\n",
        "これで ``train_data`` が定義できたので ``torchtext`` の ``Field`` の非常に便利な機能を見ることができます。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnyHyjTUjrk_",
        "colab": {}
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq = 2)\n",
        "TRG.build_vocab(train_data, min_freq = 2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kAphOHC0jrlG"
      },
      "source": [
        "<!--\n",
        "Once these lines of code have been run, ``SRC.vocab.stoi`` will  be a dictionary with the tokens in the vocabulary as keys and their corresponding indices as values; \n",
        "``SRC.vocab.itos`` will be the same dictionary with the keys and values swapped. \n",
        "We won't make extensive use of this fact in this tutorial, but this will likely be useful in other NLP tasks you'll encounter.\n",
        "-->\n",
        "\n",
        "これらのコードを実行すると、 ``SRC.vocab.stoi`` は語彙のトークンをキーとし，それに対応するインデックスを値として持つ辞書になります。\n",
        "``SRC.vocab.itos`` は同じ辞書で，キーと値が入れ替わっています。\n",
        "このチュートリアルではこの事実を大々的に利用することはありませんが、他の NLP 課題で遭遇することには役立つでしょう。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BOri4gCIjrlH"
      },
      "source": [
        "## ``BucketIterator``\n",
        "<!--\n",
        "The last ``torchtext`` specific feature we'll use is the ``BucketIterator``, which is easy to use since it takes a ``TranslationDataset`` as its first argument. \n",
        "Specifically, as the docs say:\n",
        "Defines an iterator that batches examples of similar lengths together.\n",
        "Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch. See pool for the bucketing procedure used.\n",
        "-->\n",
        "\n",
        "最後に ``torchtext`` に特有の機能として ``BucketIterator`` を使うことにしました。\n",
        "具体的には、ドキュメントに書かれている通りです:\n",
        "似たような長さの例をまとめるイテレータを定義します。\n",
        "新しいエポックごとに新しくシャッフルされたバッチを生成し，必要とされるパディングの量を最小限に抑えます。\n",
        "使用されるバケット処理については pool を参照してください。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cN9RveH0jrlJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aad2b31e-64f8-45a1-ca17-a4706c2169b6"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    device = device)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TScX_DH8jrlV"
      },
      "source": [
        "<!--\n",
        "These iterators can be called just like ``DataLoader``s; below, in the ``train`` and ``evaluate`` functions, they are called simply with:\n",
        "-->\n",
        "\n",
        "これらのイテレータは ``DataLoader``s と同様に呼び出すことができます; \n",
        "以下では ``train`` と ``evaluate`` 関数の中で、単に ``train`` と ``evaluate`` を使って呼び出されます。\n",
        "\n",
        "```python\n",
        "   for i, batch in enumerate(iterator):\n",
        "```\n",
        "\n",
        "<!--Each ``batch`` then has ``src`` and ``trg`` attributes:-->\n",
        "各 ``batch`` は ``src`` と ``trg`` 属性を持ちます:\n",
        "\n",
        "```python\n",
        "   src = batch.src\n",
        "   trg = batch.trg\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kgDDuweqjrlW"
      },
      "source": [
        "<!--\n",
        "## Defining our ``nn.Module`` and ``Optimizer``\n",
        "-->\n",
        "\n",
        "## ``nn.Module`` と ``Optimizer`` の定義\n",
        "\n",
        "<!--\n",
        "That's mostly it from a ``torchtext`` perspecive: with the dataset built and the iterator defined, the rest of this tutorial simply defines our model as an ``nn.Module``, along with an ``Optimizer``, and then trains it.\n",
        "-->\n",
        "\n",
        "これが ``torchtext`` の観点から見た場合の大部分です。\n",
        "このチュートリアルの残りの部分では，構築したデータセットと定義したイテレータを用いることで，ただモデルを ``nn.Module`` と ``Optimizer`` とを使って ``nn.Module`` として定義し、学習するだけです。\n",
        "\n",
        "ここでのモデルは，[Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473) で提案されたアーキテクチャを採用しています。\n",
        "更に [このノートブック](https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb) も参照してください)\n",
        "\n",
        "<!--\n",
        "Our model specifically, follows the architecture described [here](https://arxiv.org/abs/1409.0473) (you can find a significantly more commented version [here](https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/3%20-%20Neural%20Machine%20Translation%20by%20Jointly%20Learning%20to%20Align%20and%20Translate.ipynb)).\n",
        "-->\n",
        "\n",
        "#### 覚書:\n",
        "<!--#### Note: -->\n",
        "<!--\n",
        "this model is just an example model that can be used for language translation; \n",
        "we choose it because it is a standard model for the task, not because it is the recommended model to use for translation. \n",
        "As you're  likely aware, state-of-the-art models are currently based on Transformers; \n",
        "you can see PyTorch's capabilities for implementing Transformer layers [here](https://pytorch.org/docs/stable/nn.html#transformer-layers); and in particular, the \"attention\" used in the model below is different from the multi-headed self-attention present in a transformer model.\n",
        "-->\n",
        "\n",
        "このモデルは，言語翻訳に使用できるモデルの一例に過ぎません。\n",
        "私たちがこのモデルを選んだのは，この課題の標準モデルだからです。\n",
        "ですがこのモデルは，翻訳に使用する推奨モデルではありません。\n",
        "ご存知のように，最先端のモデルは現在 Transformer をベースにしています。\n",
        "PyTorch の Transformer 層の実装は [こちら](https://pytorch.org/docs/stable/nn.html#transformer-layers) から見ることができます。\n",
        "\n",
        "特に，以下のモデルで使用されている「注意」は、Transformer モデルでの多頭自己注意とは異なります。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSJGgUb4YLXo",
        "colab_type": "text"
      },
      "source": [
        "(訳注)\n",
        "Seq2Seq モデルについては直上セルにあるとおり，Seth H. Weidman のコードが元になっている。\n",
        "Wiedman のノートブックにあるとおり Seq2Seq モデルのプロトタイプは下図のとおりである\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/SethHWeidman/pytorch-seq2seq/master/assets/seq2seq1.png\" style=\"width:49%\">\n",
        "\n",
        "In the previous model, our architecture was set-up in a way to reduce \"information compression\" by explicitly passing the context vector, $z$, to the decoder at every time-step and by passing both the context vector and input word, $y_t$, along with the hidden state, $s_t$, to the linear layer, $f$, to make a prediction.\n",
        "\n",
        "前モデルでは、文脈ベクトル $z$ を時間ステップごとに明示的にデコーダに渡し，文脈ベクトルと 入力語 $y_t$ との両方を，隠れ層状態 $s_t$ とともに線形層 $f$ に渡して予測を行うことで，「情報圧縮」を減らすようにアーキテクチャを設定していた。\n",
        "しかし，このモデルでは，文脈ベクトルと入力語 $y_t$ との両方を 隠れ状態 $s_t$ とともに線形層 $f$ に渡して予測を行うようにした。\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/SethHWeidman/pytorch-seq2seq/master/assets/seq2seq7.png\" style=\"width:49%\">\n",
        "\n",
        "<!--\n",
        "Even though we have reduced some of this compression, our context vector still needs to contain all of the information about the source sentence. The model implemented in this notebook avoids this compression by allowing the decoder to look at the entire source sentence (via its hidden states) at each decoding step! How does it do this? It uses attention.\n",
        "-->\n",
        "\n",
        "この圧縮を一部削減したとはいえ，文脈ベクトルには原文に関するすべての情報が含まれている必要があります。\n",
        "このノートブックで実装されているモデルは，デコーダが各デコードステップで（隠れ層の状態を介して）原文全体を見ることを可能にすることで，この圧縮を回避しています。\n",
        "どうやってこれを行うのでしょうか？それには，注意を持ちています。\n",
        "\n",
        "<!--Attention works by first, calculating an attention vector, $a$, that is the length of the source sentence. The attention vector has the property that each element is between 0 and 1, and the entire vector sums to 1. We then calculate a weighted sum of our source sentence hidden states, $H$, to get a weighted source vector, $w$.\n",
        "-->\n",
        "\n",
        "注意は，まず，原文の長さである注意ベクトル $a$ を計算します。\n",
        "注意ベクトルは，各要素が 0 から 1 の間にあり，ベクトル全体の和が 1 になるという性質を持っています。\n",
        "次に、原文の隠れ層状態の加重和 $h$ を計算し，加重された原文ベクトル $w$ を求めます。\n",
        "\n",
        "$$w = \\sum_{i}a_ih_i$$\n",
        "\n",
        "We calculate a new weighted source vector every time-step when decoding, using it as input to our decoder RNN as well as the linear layer to make a prediction. We'll explain how to do all of this during the tutorial.\n",
        "\n",
        "デコードする際，予測を行う線形層と同様，デコーダ RNN への入力として注意の重みを使用して，タイムステップごとに新しい重み付けされたソースベクトルを計算します。\n",
        "このチュートリアルでは，これらすべてをどのように行うかを説明します。\n",
        "\n",
        "---\n",
        "\n",
        "ここからが本当の訳注: Weidman は上記のように説明していますが，この注意こそがは Bahdanau らの導入した[注意](https://arxiv.org/abs/1409.0473)である。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zXEm3QokjrlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e934f3b-bda9-43e4-d207-5aca3926ea32"
      },
      "source": [
        "import random\n",
        "from typing import Tuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: float):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
        "\n",
        "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        embedded = self.dropout(self.embedding(src))\n",
        "\n",
        "        outputs, hidden = self.rnn(embedded)\n",
        "\n",
        "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 attn_dim: int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "\n",
        "        self.attn_in = (enc_hid_dim * 2) + dec_hid_dim\n",
        "\n",
        "        self.attn = nn.Linear(self.attn_in, attn_dim)\n",
        "\n",
        "    def forward(self,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        src_len = encoder_outputs.shape[0]\n",
        "\n",
        "        repeated_decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        energy = torch.tanh(self.attn(torch.cat((\n",
        "            repeated_decoder_hidden,\n",
        "            encoder_outputs),\n",
        "            dim = 2)))\n",
        "\n",
        "        attention = torch.sum(energy, dim=2)\n",
        "\n",
        "        return F.softmax(attention, dim=1)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 emb_dim: int,\n",
        "                 enc_hid_dim: int,\n",
        "                 dec_hid_dim: int,\n",
        "                 dropout: int,\n",
        "                 attention: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.enc_hid_dim = enc_hid_dim\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.dropout = dropout\n",
        "        self.attention = attention\n",
        "\n",
        "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
        "\n",
        "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
        "\n",
        "        self.out = nn.Linear(self.attention.attn_in + emb_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "    def _weighted_encoder_rep(self,\n",
        "                              decoder_hidden: Tensor,\n",
        "                              encoder_outputs: Tensor) -> Tensor:\n",
        "\n",
        "        a = self.attention(decoder_hidden, encoder_outputs)\n",
        "\n",
        "        a = a.unsqueeze(1)\n",
        "\n",
        "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
        "\n",
        "        weighted_encoder_rep = torch.bmm(a, encoder_outputs)\n",
        "\n",
        "        weighted_encoder_rep = weighted_encoder_rep.permute(1, 0, 2)\n",
        "\n",
        "        return weighted_encoder_rep\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "                input: Tensor,\n",
        "                decoder_hidden: Tensor,\n",
        "                encoder_outputs: Tensor) -> Tuple[Tensor]:\n",
        "\n",
        "        input = input.unsqueeze(0)\n",
        "\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        weighted_encoder_rep = self._weighted_encoder_rep(decoder_hidden,\n",
        "                                                          encoder_outputs)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, weighted_encoder_rep), dim = 2)\n",
        "\n",
        "        output, decoder_hidden = self.rnn(rnn_input, decoder_hidden.unsqueeze(0))\n",
        "\n",
        "        embedded = embedded.squeeze(0)\n",
        "        output = output.squeeze(0)\n",
        "        weighted_encoder_rep = weighted_encoder_rep.squeeze(0)\n",
        "\n",
        "        output = self.out(torch.cat((output,\n",
        "                                     weighted_encoder_rep,\n",
        "                                     embedded), dim = 1))\n",
        "\n",
        "        return output, decoder_hidden.squeeze(0)\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self,\n",
        "                 encoder: nn.Module,\n",
        "                 decoder: nn.Module,\n",
        "                 device: torch.device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                teacher_forcing_ratio: float = 0.5) -> Tensor:\n",
        "\n",
        "        batch_size = src.shape[1]\n",
        "        max_len = trg.shape[0]\n",
        "        trg_vocab_size = self.decoder.output_dim\n",
        "\n",
        "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
        "\n",
        "        encoder_outputs, hidden = self.encoder(src)\n",
        "\n",
        "        # first input to the decoder is the <sos> token\n",
        "        output = trg[0,:]\n",
        "\n",
        "        for t in range(1, max_len):\n",
        "            output, hidden = self.decoder(output, hidden, encoder_outputs)\n",
        "            outputs[t] = output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            top1 = output.max(1)[1]\n",
        "            output = (trg[t] if teacher_force else top1)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "INPUT_DIM = len(SRC.vocab)\n",
        "OUTPUT_DIM = len(TRG.vocab)\n",
        "# ENC_EMB_DIM = 256\n",
        "# DEC_EMB_DIM = 256\n",
        "# ENC_HID_DIM = 512\n",
        "# DEC_HID_DIM = 512\n",
        "# ATTN_DIM = 64\n",
        "# ENC_DROPOUT = 0.5\n",
        "# DEC_DROPOUT = 0.5\n",
        "\n",
        "ENC_EMB_DIM = 32\n",
        "DEC_EMB_DIM = 32\n",
        "ENC_HID_DIM = 64\n",
        "DEC_HID_DIM = 64\n",
        "ATTN_DIM = 8\n",
        "ENC_DROPOUT = 0.5\n",
        "DEC_DROPOUT = 0.5\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT)\n",
        "\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_DIM, ATTN_DIM)\n",
        "\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn)\n",
        "\n",
        "model = Seq2Seq(enc, dec, device).to(device)\n",
        "\n",
        "\n",
        "def init_weights(m: nn.Module):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "\n",
        "def count_parameters(model: nn.Module):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 1,856,685 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "T9Z3kR7pjrlZ"
      },
      "source": [
        "<!--\n",
        "Note: when scoring the performance of a language translation model in particular, we have to tell the ``nn.CrossEntropyLoss`` function to ignore the indices where the target is simply padding.\n",
        "-->\n",
        "\n",
        "覚書: 特に言語翻訳モデルの性能をスコアリングする際には ``nn.CrossEntropyLoss`` 関数に，対象が単にパディングしているだけのインデックスを無視するように指示しなければなりません．\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NhQJkg2_jrla",
        "colab": {}
      },
      "source": [
        "PAD_IDX = TRG.vocab.stoi['<pad>']\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uW-qY3Vwjrli"
      },
      "source": [
        "<!---Finally, we can train and evaluate this model:-->\n",
        "これで，モデル学習と評価ができます\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rs8KvuH1jrlj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "6495dbea-c12e-4f13-a329-f85a31ab02dd"
      },
      "source": [
        "import math\n",
        "import time\n",
        "\n",
        "\n",
        "def train(model: nn.Module,\n",
        "          iterator: BucketIterator,\n",
        "          optimizer: optim.Optimizer,\n",
        "          criterion: nn.Module,\n",
        "          clip: float):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for _, batch in enumerate(iterator):\n",
        "\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(src, trg)\n",
        "\n",
        "        output = output[1:].view(-1, output.shape[-1])\n",
        "        trg = trg[1:].view(-1)\n",
        "\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model: nn.Module,\n",
        "             iterator: BucketIterator,\n",
        "             criterion: nn.Module):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for _, batch in enumerate(iterator):\n",
        "\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\n",
        "\n",
        "            output = output[1:].view(-1, output.shape[-1])\n",
        "            trg = trg[1:].view(-1)\n",
        "\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def epoch_time(start_time: int,\n",
        "               end_time: int):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs\n",
        "\n",
        "\n",
        "N_EPOCHS = 10\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
        "\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 28s\n",
            "\tTrain Loss: 5.687 | Train PPL: 295.101\n",
            "\t Val. Loss: 5.248 |  Val. PPL: 190.218\n",
            "Epoch: 02 | Time: 0m 28s\n",
            "\tTrain Loss: 5.026 | Train PPL: 152.327\n",
            "\t Val. Loss: 5.065 |  Val. PPL: 158.323\n",
            "Epoch: 03 | Time: 0m 29s\n",
            "\tTrain Loss: 4.751 | Train PPL: 115.718\n",
            "\t Val. Loss: 4.960 |  Val. PPL: 142.574\n",
            "Epoch: 04 | Time: 0m 28s\n",
            "\tTrain Loss: 4.592 | Train PPL:  98.737\n",
            "\t Val. Loss: 5.017 |  Val. PPL: 150.956\n",
            "Epoch: 05 | Time: 0m 29s\n",
            "\tTrain Loss: 4.496 | Train PPL:  89.663\n",
            "\t Val. Loss: 4.962 |  Val. PPL: 142.874\n",
            "Epoch: 06 | Time: 0m 29s\n",
            "\tTrain Loss: 4.378 | Train PPL:  79.701\n",
            "\t Val. Loss: 4.966 |  Val. PPL: 143.420\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JAheQMRajrly"
      },
      "source": [
        "<!--\n",
        "## Next steps\n",
        "\n",
        "- Check out the rest of Ben Trevett's tutorials using ``torchtext`` [here](https://github.com/bentrevett/)\n",
        "- Stay tuned for a tutorial using other ``torchtext`` features along   with ``nn.Transformer`` for language modeling via next word prediction!\n",
        "-->\n",
        "\n",
        "## 次のステップ\n",
        "\n",
        "- Ben Trevett の残りの ``torchtext`` を使ったチュートリアルをチェックしてみてください [https://github.com/bentrevett/](https://github.com/bentrevett/)\n",
        "- 次単語予測による言語モデリングを用いた，その他の ``torchtext`` の機能と ``nn.Transformer`` を使ったチュートリアルをお楽しみに!\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TctUJv5uYLX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}