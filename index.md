---
layout: home
title: "Welcome to JPA BERT"
---

このページは 2020年度日本心理学会チュートリアルワークショップ BERT 入門のページです。

## 講演タイトル: 心理学におけるBERT入門

## 要旨

[BERT](https://arxiv.org/abs/1810.04805){:target="_blank"}  は自然言語処理モデルであり，この分野の流れを塗り替えてしまったゲームチェンジャーである。
本チュートリアルワークショップでは [Colab](https://arxiv.org/abs/1810.04805){:target="_blank"} を使用した BERT の実習を通じてその可能性を 探る。
BERT は自己注意に基づくモデルであり，一般的な知識を獲得する事前学習と個々の下流課 題に対するファインチューニングを特徴とする。
これらの特徴は，心理学徒も議論してきた中心的 課題である。
この意味で心理学との架け橋となる可能性を有していると考えられる。
語彙判断課題，プライミングなどの心理実験とそれらのモデルへの応用についても議論する。
参加者には colab, python, [PyTorch](https://pytorch.org/){:target="_blank"} での実習を予定しているが特別な事前知識は仮定しない。
実習を行う環境 としてブラウザ Chrome をご準備いただくが，それ以外の事前準備は不要である。
関心を共有する 諸賢の参加を呼びかける。


- [導入](intro.html)
- [Colab notebooks ソースコード置き場](notebooks)
- [スライド1](/slides/2020jpa-bert_slides.html)
- [スライド2](/slides/2020jpa-bert_slides2.html#(2))

---
<br/>

## 補助資料

### 簡単なデモ プレイグラウンド

ニューラルネットワークに慣れる目的で，CNN と RNN のプレイグラウンドアプリを紹介します。

- [TensorFlow Playgournd ニューラルネットワークの基本](/tensorflow-playground)
- [リカレントニューラルネットワークによる文字ベース言語モデル Javascript](https://komazawa-deep-learning.github.io/character_demo.html)
- [効率良く t-SNE を使う方法](https://project-ccap.github.io/misread-tsne/index.html)

### [2019年認知神経心理学研究会](https://www.cis.twcu.ac.jp/~asakawa/2019cnps_handson/) 資料より抜粋

- [Colab についての蘊蓄](supp01_colab)
- [Colab による外部ファイルとのインタフェース](supp02_colab_file_management)
- [Python と numpy の初歩](python_numpy_intro_ja)
- [CNN についての蘊蓄](supp05_cnn)
- [RNN についての蘊蓄](supp06_rnn)
- [NLP についての蘊蓄](supp07_nlp)

<br/>

---
<br/>

- [大会ページ](http://jpa2020.com/)
